{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scgpt as scg\n",
    "import torch as tc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from pathlib import Path\n",
    "from torch.autograd import Function\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn \n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_genes = pd.read_parquet('../data/MERGED_normalized_5000genesTIERS.parquet').drop(columns = ['Tier_1', 'Tier_2', 'Tier_3', 'Tier_4'])\n",
    "ground_truth_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_raw = pd.read_parquet('../data/Metastasized_5000genesTIERS.parquet')#.iloc[:500,:]\n",
    "dat_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_aligned = pd.DataFrame(columns=ground_truth_genes.columns)\n",
    "df_new_aligned = pd.concat((df_new_aligned, dat_raw), axis=0)\n",
    "df_new_aligned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = df_new_aligned.iloc[:,2:]\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DS(Dataset):\n",
    "    def __init__(self, df, patients):\n",
    "        self.df = df \n",
    "\n",
    "        self.patients = np.array(patients)\n",
    "        self.unique_patients = patients.drop_duplicates().to_numpy()\n",
    "\n",
    "        self.data_tensor = tc.FloatTensor((self.df.values.astype(float)))\n",
    "        self.data_tensor = tc.nan_to_num(self.data_tensor,0.0)\n",
    "\n",
    "\n",
    "        self.data_dict = {patient: self.data_tensor[self.patients == patient,:] for patient in tqdm(self.unique_patients[:])}\n",
    "\n",
    "        self.patient_ids_dict = {patient: self.make_one_hot(self.unique_patients.shape[0], i) for i,patient in enumerate(self.unique_patients)}\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_dict)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        current_data_tensor =  self.data_dict[self.unique_patients[idx]]\n",
    "        nsamples = current_data_tensor.shape[0]\n",
    "\n",
    "\n",
    "        current_patient_id = self.patient_ids_dict[self.unique_patients[idx]]\n",
    "        \n",
    "        if current_data_tensor.shape[0]>2000:\n",
    "            return current_data_tensor[tc.randperm(nsamples)[:2000],:], current_patient_id * tc.ones(2000,1)\n",
    "\n",
    "        print(idx)\n",
    "\n",
    "        return current_data_tensor[tc.randperm(nsamples),:], current_patient_id * tc.ones(nsamples,1)\n",
    "\n",
    "\n",
    "    def make_one_hot(self, length, idx):\n",
    "        x = tc.zeros(length)\n",
    "        x[idx]=1\n",
    "        return x\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseLayerF(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "\n",
    "        return output, None\n",
    "    \n",
    "    \n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(self, inp, hidden, outp):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "                    #nn.Dropout(0.2),          #0.5\n",
    "                    nn.Linear(inp, hidden), \n",
    "                    nn.BatchNorm1d(hidden),\n",
    "                    nn.LeakyReLU(), \n",
    "                    nn.Dropout(0.2),      \n",
    "                    nn.Linear(hidden, hidden),\n",
    "                    nn.BatchNorm1d(hidden),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.Dropout(0.2),      \n",
    "                    nn.Linear(hidden, hidden),\n",
    "                    nn.BatchNorm1d(hidden),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.Dropout(0.2),      \n",
    "                    nn.Linear(hidden, 1000),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.Dropout(0.2),      \n",
    "                    nn.Linear(1000, outp))\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.layers(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, inp, hidden, npatients):\n",
    "        super().__init__()\n",
    "\n",
    "        self.npatients = npatients\n",
    "        self.backbone = Backbone(inp, hidden, 64)\n",
    "        \n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(64, 512), \n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512,512))\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64,512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, self.npatients)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "\n",
    "\n",
    "        def off_diagonal(arr):\n",
    "            n = len(arr)\n",
    "            return arr.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
    "\n",
    "        x = self.projector(self.backbone(x))\n",
    "        y = self.projector(self.backbone(y))\n",
    "\n",
    "\n",
    "        repr_loss = F.mse_loss(x, y)  # invariance (2)\n",
    "        x = x - x.mean(dim=0)\n",
    "        y = y - y.mean(dim=0)\n",
    "        \n",
    "\n",
    "        std_x = tc.sqrt(x.var(dim=0) + 0.0001)  # variance (1)\n",
    "        std_y = tc.sqrt(y.var(dim=0) + 0.0001)\n",
    "        std_loss = tc.mean(F.relu(1 - std_x)) / 2 + tc.mean(F.relu(1 - std_y)) / 2\n",
    "\n",
    "        cov_x = (x.T @ x) / (len(x) - 1) # covariance (3)\n",
    "        cov_y = (y.T @ y) / (len(y) - 1)\n",
    "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(\n",
    "            256) + off_diagonal(cov_y).pow_(2).sum().div(256)\n",
    "\n",
    "        \n",
    "        loss = (25. * repr_loss + 25. * std_loss + 1. * cov_loss)\n",
    "        return loss\n",
    "\n",
    "    def dal(self, x,patient_y):\n",
    "\n",
    "        x = self.backbone(x)\n",
    "        reverse_x =  ReverseLayerF.apply(x, 1.0)\n",
    "\n",
    "        y_hat = self.classifier(reverse_x)\n",
    "                \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss = criterion(y_hat, patient_y,)\n",
    "\n",
    "\n",
    "        return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DS(dat, dat_raw['Pseudo'])\n",
    "#model = Model(dat.shape[1], 5000, npatients = ds.unique_patients.shape[0])\n",
    "dl = DataLoader(ds, batch_size = 1, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(dat.shape[1], 5000, npatients = 365) #npatients: only from old training approach to include domain adversarial loss\n",
    "\n",
    "model.load_state_dict(tc.load('./save/vicreg/model_per_patient_batchnorm_highinputdropout' + str('5000') + '.pt', map_location=tc.device('cpu')) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DS(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df \n",
    "\n",
    "        self.data_tensor = tc.FloatTensor((self.df.values.astype(float)))\n",
    "        self.data_tensor = tc.nan_to_num(self.data_tensor,0.0)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_tensor.shape[0]\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_tensor[idx,:]\n",
    "\n",
    "ds = DS(dat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "device = tc.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dl = DataLoader(ds, batch_size = 5000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval().to(device)\n",
    "with tc.no_grad():\n",
    "    embeddings = pd.DataFrame(np.array(tc.cat([model.backbone.forward(X.to(device)).cpu() for X in tqdm(embedding_dl)], axis=0)))\n",
    "\n",
    "embeddings.columns = ['D' + str(column) for column in embeddings.columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_frame = pd.concat((dat_raw.iloc[:,:2], embeddings), axis=1)\n",
    "embeddings_frame.to_parquet('./embeddings/VICREG_embedding_validation_external.parquet')\n",
    "embeddings_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scgpt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
